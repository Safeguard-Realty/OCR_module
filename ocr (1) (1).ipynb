{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfrTsgDO1GAv",
        "outputId": "c13b8cfb-8173-4781-cdaf-57dda9ada9c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyPDF2 in c:\\users\\prath\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (3.0.1)\n",
            "Requirement already satisfied: pytesseract in c:\\users\\prath\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (0.3.13)\n",
            "Requirement already satisfied: pillow in c:\\users\\prath\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (10.4.0)\n",
            "Requirement already satisfied: packaging>=21.3 in c:\\users\\prath\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from pytesseract) (24.1)\n",
            "Requirement already satisfied: easyocr in c:\\users\\prath\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (1.7.1)\n",
            "Requirement already satisfied: torch in c:\\users\\prath\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from easyocr) (2.4.1)\n",
            "Requirement already satisfied: torchvision>=0.5 in c:\\users\\prath\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from easyocr) (0.19.1)\n",
            "Requirement already satisfied: opencv-python-headless in c:\\users\\prath\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from easyocr) (4.10.0.84)\n",
            "Requirement already satisfied: scipy in c:\\users\\prath\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from easyocr) (1.14.1)\n",
            "Requirement already satisfied: numpy in c:\\users\\prath\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from easyocr) (1.26.4)\n",
            "Requirement already satisfied: Pillow in c:\\users\\prath\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from easyocr) (10.4.0)\n",
            "Requirement already satisfied: scikit-image in c:\\users\\prath\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from easyocr) (0.24.0)\n",
            "Requirement already satisfied: python-bidi in c:\\users\\prath\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from easyocr) (0.6.0)\n",
            "Requirement already satisfied: PyYAML in c:\\users\\prath\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from easyocr) (6.0.1)\n",
            "Requirement already satisfied: Shapely in c:\\users\\prath\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from easyocr) (2.0.6)\n",
            "Requirement already satisfied: pyclipper in c:\\users\\prath\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from easyocr) (1.3.0.post5)\n",
            "Requirement already satisfied: ninja in c:\\users\\prath\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from easyocr) (1.11.1.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\prath\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from torch->easyocr) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\prath\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from torch->easyocr) (4.11.0)\n",
            "Requirement already satisfied: sympy in c:\\users\\prath\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from torch->easyocr) (1.13.2)\n",
            "Requirement already satisfied: networkx in c:\\users\\prath\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from torch->easyocr) (3.3)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\prath\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from torch->easyocr) (3.1.4)\n",
            "Requirement already satisfied: fsspec in c:\\users\\prath\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from torch->easyocr) (2024.6.1)\n",
            "Requirement already satisfied: setuptools in c:\\users\\prath\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from torch->easyocr) (72.1.0)\n",
            "Requirement already satisfied: imageio>=2.33 in c:\\users\\prath\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from scikit-image->easyocr) (2.35.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\prath\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from scikit-image->easyocr) (2024.8.30)\n",
            "Requirement already satisfied: packaging>=21 in c:\\users\\prath\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from scikit-image->easyocr) (24.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\prath\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from scikit-image->easyocr) (0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\prath\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from jinja2->torch->easyocr) (2.1.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\prath\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages (from sympy->torch->easyocr) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install PyPDF2 pytesseract pillow\n",
        "!pip install easyocr\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "978mQp3E-fhU"
      },
      "source": [
        "## preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RbIF-c1nSAv5"
      },
      "outputs": [],
      "source": [
        "import PyPDF2\n",
        "import easyocr\n",
        "from PIL import Image, ImageEnhance, ImageOps, ImageFilter\n",
        "import cv2\n",
        "import numpy as np\n",
        "import re\n",
        "import os\n",
        "import io\n",
        "\n",
        "def preprocess_image(img_path):\n",
        "    \"\"\"\n",
        "    Preprocess the image for better OCR results.\n",
        "    Steps: Grayscale -> Resize -> Adaptive Threshold -> Sharpen -> Auto Contrast\n",
        "    \"\"\"\n",
        "    # Load with OpenCV\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # Resize for better OCR accuracy\n",
        "    img = cv2.resize(img, None, fx=2, fy=2, interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "    # Apply adaptive thresholding\n",
        "    img = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "                                cv2.THRESH_BINARY, 31, 15)\n",
        "\n",
        "    # Convert back to PIL Image for further enhancements\n",
        "    img = Image.fromarray(img)\n",
        "    img = ImageEnhance.Sharpness(img).enhance(2.0)  # Sharpen\n",
        "    img = ImageOps.autocontrast(img)  # Auto Contrast\n",
        "\n",
        "    return np.array(img)  # Return as numpy array for OCR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JoTuduai3gQz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "ZpvJeYF116G2"
      },
      "outputs": [],
      "source": [
        "def extract_key_data(results):\n",
        "    \"\"\"\n",
        "    Extracts structured data with enhanced logic to extract Aadhaar numbers split across lines\n",
        "    and the corresponding name above the Aadhaar number or DOB.\n",
        "    \"\"\"\n",
        "    doc_type = None\n",
        "    aadhaar_number = \"\"\n",
        "    pan_number = \"\"\n",
        "    passport_number = \"\"\n",
        "    dates = []\n",
        "    name = \"\"\n",
        "    father_name = \"\"\n",
        "\n",
        "    dob_line_index = -1\n",
        "    id_number_index = -1\n",
        "    aadhaar_parts = []\n",
        "\n",
        "    for i, text in enumerate(results):\n",
        "        text = text.strip()\n",
        "\n",
        "         # Full Aadhaar number in one line\n",
        "        if re.match(r'^\\d{4}\\s\\d{4}\\s\\d{4}$', text):\n",
        "            doc_type = 'aadhaar'\n",
        "            aadhaar_number = text.replace(' ', '')\n",
        "            id_number_index = i\n",
        "            continue\n",
        "\n",
        "        # Partial Aadhaar numbers\n",
        "        if re.match(r'^\\d{4}(\\s\\d{4})?$', text):\n",
        "            aadhaar_parts.append(text.replace(' ', ''))\n",
        "            if len(''.join(aadhaar_parts)) == 12:\n",
        "                doc_type = 'aadhaar'\n",
        "                aadhaar_number = ''.join(aadhaar_parts)\n",
        "                id_number_index = i\n",
        "                aadhaar_parts = []\n",
        "            elif len(''.join(aadhaar_parts)) > 12:\n",
        "                aadhaar_parts = []\n",
        "\n",
        "\n",
        "        # Detect PAN number\n",
        "        elif re.match(r'^[A-Z]{5}\\d{4}[A-Z]$', text):\n",
        "            doc_type = 'pan'\n",
        "            pan_number = text\n",
        "            id_number_index = i\n",
        "        # Add this in the main loop after PAN number detection but before the date logic:\n",
        "\n",
        "        # Passport number detection\n",
        "        if re.match(r'^[A-Z]\\d{7}$', text):\n",
        "            doc_type = 'passport'\n",
        "            passport_number = text\n",
        "            id_number_index = i\n",
        "\n",
        "        # Passport name detection (add this in the name detection section)\n",
        "        elif doc_type == 'passport':\n",
        "            # Look for surname\n",
        "            if 'Surname' in text or any(word in text for word in ['RAI', 'SINGH', 'KUMAR']):\n",
        "                surname_line = i\n",
        "                surname = text.split('/')[-1].strip()\n",
        "\n",
        "            # Look for given names\n",
        "            elif 'Given Names' in text or 'GIVEN NAMES' in text:\n",
        "                given_name_line = i\n",
        "                if i + 1 < len(results):\n",
        "                    given_name = results[i + 1].strip()\n",
        "                    if given_name and re.match(r'^[A-Z\\s]+$', given_name):\n",
        "                        if surname:\n",
        "                            name = f\"{given_name} {surname}\"\n",
        "                        else:\n",
        "                            name = given_name\n",
        "\n",
        "# Modify the date extraction logic to handle passport dates:\n",
        "\n",
        "        # Date extraction for passport\n",
        "        if doc_type == 'passport':\n",
        "            date_match = re.search(r'\\d{2}/\\d{2}/\\d{4}', text)\n",
        "            if date_match:\n",
        "                date = date_match.group(0)\n",
        "                if date not in dates:\n",
        "                    dates.append(date)\n",
        "                    print(f\"Identified Passport Date: {date}\")\n",
        "\n",
        "            # Look for specific passport date markers\n",
        "            if 'Date of Birth' in text or 'DOB' in text:\n",
        "                dob_line_index = i\n",
        "                if i + 1 < len(results):\n",
        "                    next_line = results[i + 1].strip()\n",
        "                    date_match = re.search(r'\\d{2}/\\d{2}/\\d{4}', next_line)\n",
        "                    if date_match and date_match.group(0) not in dates:\n",
        "                        dates.insert(0, date_match.group(0))  # Ensure DOB is first\n",
        "\n",
        "            if 'Date of Issue' in text:\n",
        "                if i + 1 < len(results):\n",
        "                    next_line = results[i + 1].strip()\n",
        "                    date_match = re.search(r'\\d{2}/\\d{2}/\\d{4}', next_line)\n",
        "                    if date_match:\n",
        "                        issue_date = date_match.group(0)\n",
        "                        if issue_date not in dates:\n",
        "                            dates.append(issue_date)\n",
        "\n",
        "            if 'Date of Expiry' in text:\n",
        "                if i + 1 < len(results):\n",
        "                    next_line = results[i + 1].strip()\n",
        "                    date_match = re.search(r'\\d{2}/\\d{2}/\\d{4}', next_line)\n",
        "                    if date_match:\n",
        "                        expiry_date = date_match.group(0)\n",
        "                        if expiry_date not in dates:\n",
        "                            dates.append(expiry_date)\n",
        "\n",
        "        date_match = re.search(r'\\d{2}[/\\-\\.]\\d{2}[/\\-\\.]\\d{4}', text)\n",
        "        if date_match:\n",
        "            date = date_match.group(0)\n",
        "            if date not in dates:\n",
        "                dates.append(date)\n",
        "                print(f\"Identified Date from line: {date}\")\n",
        "\n",
        "        # Check for DOB markers and surrounding lines\n",
        "        if any(marker in text.upper() for marker in ['DOB', 'जन्म', 'DATE OF BIRTH', 'BIRTH']):\n",
        "            dob_line_index = i\n",
        "            # Check current line again with more flexible pattern\n",
        "            date_match = re.search(r'.*?(\\d{2}[/\\-\\.]\\d{2}[/\\-\\.]\\d{4})', text)\n",
        "\n",
        "            if date_match:\n",
        "                date = date_match.group(1)\n",
        "                if date not in dates:\n",
        "                    dates.append(date)\n",
        "                    print(f\"Identified Date from DOB line: {date}\")\n",
        "            else:\n",
        "                # Check surrounding lines (2 lines before and 2 lines after)\n",
        "                for offset in [-2, -1, 1, 2]:\n",
        "                    check_index = i + offset\n",
        "                    if 0 <= check_index < len(results):\n",
        "                        check_line = results[check_index].strip()\n",
        "                        # More flexible date pattern to handle special characters\n",
        "                        date_match = re.search(r'.*?(\\d{2}[/\\-\\.]\\d{2}[/\\-\\.]\\d{4})', check_line)\n",
        "                        if date_match:\n",
        "                            date = date_match.group(1)\n",
        "                            if date not in dates:\n",
        "                                dates.append(date)\n",
        "                                print(f\"Identified Date from offset line {offset}: {date}\")\n",
        "                                break  # Stop after finding the first valid date\n",
        "\n",
        "    # Keep existing name and father's name detection logic\n",
        "    for i, text in enumerate(results):\n",
        "        text = text.strip()\n",
        "\n",
        "        # Skip invalid lines\n",
        "        if len(text) < 2 or re.search(r'[^A-Za-z\\s\\.]', text):\n",
        "            continue\n",
        "\n",
        "        # Name detection\n",
        "        if not name:\n",
        "            if doc_type == 'aadhaar' and dob_line_index != -1:\n",
        "                # Aadhaar name detection based on \"Government\" or \"India\"\n",
        "                if 'government' in text.lower() or 'india' in text.lower():\n",
        "                    # Check two indices below\n",
        "                    if i + 2 < len(results):\n",
        "                        potential_name = results[i + 2].strip()\n",
        "                        if (re.match(r'^[A-Za-z\\s\\.]+$', potential_name) and\n",
        "                            len(potential_name.split()) >= 2 and\n",
        "                            not any(word in potential_name.lower() for word in ['government', 'india', 'department'])):\n",
        "                            name = potential_name\n",
        "                            print(f\"Identified Name (Aadhaar): {name}\")\n",
        "                # Fallback to original Aadhaar name detection logic\n",
        "                elif (i < dob_line_index and\n",
        "                      re.match(r'^[A-Za-z\\s\\.]+$', text) and\n",
        "                      len(text.split()) >= 2 and\n",
        "                      not any(word in text.lower() for word in ['government', 'india', 'department'])):\n",
        "                    name = text\n",
        "                    print(f\"Identified Name (Aadhaar): {name}\")\n",
        "\n",
        "            elif doc_type == 'pan':\n",
        "                # PAN name detection\n",
        "                prev_line = results[i-1].strip().lower() if i > 0 else \"\"\n",
        "                if ('name' in prev_line and 'father' not in prev_line and\n",
        "                    re.match(r'^[A-Za-z\\s\\.]+$', text) and\n",
        "                    len(text.split()) >= 2):\n",
        "                    name = text\n",
        "                    print(f\"Identified Name (PAN): {name}\")\n",
        "\n",
        "        # Father's name detection\n",
        "        if not father_name:\n",
        "            prev_line = results[i-1].strip().lower() if i > 0 else \"\"\n",
        "            if (('father' in prev_line or 'पिता' in prev_line) and\n",
        "                re.match(r'^[A-Za-z\\s\\.]+$', text) and\n",
        "                len(text.split()) >= 2):\n",
        "                father_name = text\n",
        "                print(f\"Identified Father's Name: {father_name}\")\n",
        "\n",
        "    # Return extracted details\n",
        "    return {\n",
        "        \"Document Type\": doc_type,\n",
        "        \"Aadhaar Number\": aadhaar_number,\n",
        "        \"PAN Number\": pan_number,\n",
        "        \"Passport Number\": passport_number,\n",
        "        \"Dates\": dates,\n",
        "        \"Name\": name,\n",
        "        \"Father's Name\": father_name\n",
        "    }\n",
        "\n",
        "                \n",
        "        \n",
        "    # Keep existing fallback for Aadhaar name\n",
        "    \n",
        "\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDwm82ZZ76oB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "do83StBG4mRR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mutqmoZ1-ayg"
      },
      "outputs": [],
      "source": [
        "def extract_text_from_image(image_path, languages=[\"en\"], use_gpu=True):\n",
        "    \"\"\"\n",
        "    Extracts text from an image file using EasyOCR.\n",
        "    \"\"\"\n",
        "    # Initialize OCR Reader\n",
        "    reader = easyocr.Reader(languages, gpu=use_gpu)\n",
        "\n",
        "    # Preprocess the image\n",
        "    preprocessed_img = preprocess_image(image_path)\n",
        "\n",
        "    # Perform OCR\n",
        "    ocr_results = reader.readtext(preprocessed_img, detail=0)\n",
        "\n",
        "    # Extract key structured data\n",
        "    structured_data = extract_key_data(ocr_results)\n",
        "\n",
        "    return {\n",
        "        \"Structured Data\": structured_data,\n",
        "        \"Raw OCR\": ocr_results\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NY1R09Ov-XBo",
        "outputId": "58dc236d-59a3-4aee-fafd-44aec0502603"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing as Image...\n",
            "Identified Date from line: 12/08/1998\n",
            "\n",
            "Structured data saved to: extracted_data.json\n",
            "\n",
            "Structured Data:\n",
            "{\n",
            "    \"Document Type\": \"pan\",\n",
            "    \"Aadhaar Number\": \"\",\n",
            "    \"PAN Number\": \"GAZPM3729R\",\n",
            "    \"Passport Number\": \"\",\n",
            "    \"Dates\": [\n",
            "        \"12/08/1998\"\n",
            "    ],\n",
            "    \"Name\": \"\",\n",
            "    \"Father's Name\": \"\"\n",
            "}\n",
            "\n",
            "Raw OCR Output:\n",
            "3T1a57\n",
            "fatrT\n",
            "TRT\n",
            "TTR\n",
            "INCOXE TAX DEPARTMEAT\n",
            "GOVT OF INDIA\n",
            "verrut Au H1M &6\n",
            "Permanent Account Number Card\n",
            "GAZPM3729R\n",
            "TA/ Nama\n",
            "MUSKAN KHAN\n",
            "Fat #1 74\n",
            "Fother $ Namo\n",
            "AYUB KHAN\n",
            "j9cs2i20\n",
            "7 #1Tii\n",
            "Dalo of Binth\n",
            "12/08/1998\n",
            "(ran / Signaturo\n"
          ]
        }
      ],
      "source": [
        "def extract_text_from_pdf(pdf_path, languages=[\"en\"], use_gpu=True):\n",
        "    \"\"\"\n",
        "    Extracts text from a PDF, including embedded text and images.\n",
        "    \"\"\"\n",
        "    text = \"\"\n",
        "    reader = easyocr.Reader(languages, gpu=use_gpu)\n",
        "\n",
        "    with open(pdf_path, 'rb') as file:\n",
        "        pdf_reader = PyPDF2.PdfReader(file)\n",
        "        for page in pdf_reader.pages:\n",
        "            # Extract text using PyPDF2\n",
        "            page_text = page.extract_text()\n",
        "            if page_text:\n",
        "                text += page_text + \"\\n\"\n",
        "\n",
        "            # Extract images for OCR\n",
        "            if '/XObject' in page.get('/Resources', {}):\n",
        "                xObject = page['/Resources']['/XObject'].get_object()\n",
        "                for obj in xObject:\n",
        "                    if xObject[obj]['/Subtype'] == '/Image':\n",
        "                        data = xObject[obj].get_data()\n",
        "                        img = Image.open(io.BytesIO(data)) \n",
        "                        img.save(\"temp_image.png\")  # Save for processing\n",
        "\n",
        "                        # Run OCR on the image\n",
        "                        ocr_results = extract_text_from_image(\"temp_image.png\")\n",
        "                        text += \"\\n\".join(ocr_results[\"Raw OCR\"]) + \"\\n\"\n",
        "\n",
        "    # Extract structured data\n",
        "    structured_data = extract_key_data(text.splitlines())\n",
        "\n",
        "    return {\n",
        "        \"Structured Data\": structured_data,\n",
        "        \"Raw Text\": text.strip()\n",
        "    }\n",
        "\n",
        "\n",
        "import json\n",
        "\n",
        "def process_file(file_path, use_gpu=True, output_json_path=\"extracted_data.json\"):\n",
        "    \"\"\"\n",
        "    Determines the type of file (PDF or image) and processes it.\n",
        "    Saves structured data to JSON file and returns the results.\n",
        "    \"\"\"\n",
        "    file_extension = os.path.splitext(file_path)[1].lower()\n",
        "\n",
        "    if file_extension == \".pdf\":\n",
        "        print(\"Processing as PDF...\")\n",
        "        output = extract_text_from_pdf(file_path, use_gpu=use_gpu)\n",
        "    elif file_extension in [\".png\", \".jpg\", \".jpeg\", \".bmp\", \".tiff\", \".webp\"]:\n",
        "        print(\"Processing as Image...\")\n",
        "        output = extract_text_from_image(file_path, use_gpu=use_gpu)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Please provide a PDF or an image file.\")\n",
        "\n",
        "    # Save structured data to JSON file\n",
        "    with open(output_json_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(output[\"Structured Data\"], f, indent=4, ensure_ascii=False)\n",
        "\n",
        "    print(f\"\\nStructured data saved to: {output_json_path}\")\n",
        "\n",
        "    # Print the results\n",
        "    print(\"\\nStructured Data:\")\n",
        "    print(json.dumps(output[\"Structured Data\"], indent=4, ensure_ascii=False))\n",
        "    print(\"\\nRaw OCR Output:\")\n",
        "    print(\"\\n\".join(output[\"Raw OCR\"]) if \"Raw OCR\" in output else output[\"Raw Text\"])\n",
        "\n",
        "    return output\n",
        "\n",
        "# Usage\n",
        "file_path = \"pansam.jpg\"  # Replace with your file path (PDF or Image)\n",
        "try:\n",
        "    output = process_file(file_path, use_gpu=True)\n",
        "except ValueError as e:\n",
        "    print(e)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tensorflow_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
